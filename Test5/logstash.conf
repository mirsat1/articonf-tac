input {
  file {
    start_position => "beginning"
    path => "C:/Users/sefid/Desktop/testing_logstash/Test5/Offer.csv"
    sincedb_path => "NULL"
  }
}
filter {
  csv {
    columns => ["id","car","priceForKm","priceForTime","startDate","endDate","startPlacelatitude","startPlacelongitude","startPlaceAdress","endPlaces","available","startPlace"]
    convert => {
      "priceForKm" => "float"
      "priceForTime" => "float"
      "available" => "boolean"
      "startDate" => "integer"
      "endDate" => "integer"
    }
  }
  date {
    match => ["startDate", "UNIX_MS"]
    target => "@timestamp"
    timezone => "Europe/Berlin"
  }
  date {
    match => ["endDate", "UNIX_MS"]
    timezone => "Europe/Berlin"
  }
  json {
    source => "endPlaces"
    target => "endPlaces"
  }
  mutate {convert => ["startPlacelatitude", "float"]}
  mutate {convert => ["startPlacelongitude", "float"]}
  mutate {rename => ["startPlacelongitude", "[start_place][lon]"]}
  mutate {rename => ["startPlacelatitude", "[start_place][lat]"]}
  mutate {rename => ["endPlaces", "end_places"]}
}
output {
  elasticsearch {
    hosts => ["http://localhost:9200"]
    user => "elastic"
    password => "mirsat"
    index => ["agilia-offer"]
  }
  stdout { codec=>"dots" }
  if "_dateparsefailure" in [tags] {
    stdout {codec => "rubydebug"}
  }
  if "_grokparsefailure" in [tags] {
    stdout {codec => "rubydebug"}
  }
}
